# ReadX

**ReadX** is an AI assistant that helps researchers **read, analyze, and understand research papers**.
Unlike generic â€œchat with PDFâ€ tools, ReadX adds:

* **Structured metadata via GROBID** â†’ reliable title, author, and section extraction.
* **Author context** â†’ retrieve author profiles, affiliations, and past work.
* **Visual explanations** â†’ break down methods/results into diagrams and charts.
* **Cross-paper analysis** â†’ compare multiple papers side by side.
* **Persistent knowledge base** â†’ build your own library of papers you can query anytime.

---

## Features (MVP â†’ Future)

* âœ… Upload & parse PDFs (fallback: PyMuPDF, preferred: GROBID)
* âœ… Extract metadata (title, authors, abstract, venue, year)
* âœ… Store structured content in **Postgres** (papers, authors, chunks)
* âœ… Embed chunks into **VectorDB** for retrieval
* ğŸš§ LLM integration (Gemini via LangChain/LangGraph) for Q&A and synthesis
* ğŸš§ Visualization endpoints (e.g., plots from results section)
* ğŸš§ ArXiv API ingestion (auto fetch papers)
* ğŸš§ Multi-agent workflows (summarizer, author analyzer, visualizer)
* ğŸš§ Slack/Discord bot integration

---

## Architecture

See [docs/architecture.md](docs/architecture.md) for system diagrams.
Key components:

1. **Ingestion**

   * GROBID XML parsing (structured sections, references)
   * PyMuPDF heuristics (fallback when GROBID is unavailable)
2. **Storage**

   * Metadata & relationships â†’ Postgres (`papers`, `authors`, `chunks`)
   * Embeddings â†’ ChromaDB / Weaviate
3. **Orchestration**

   * LangGraph workflows for question answering, author analysis, visualization
   * Gemini as the preferred LLM backend
4. **API/UI**

   * FastAPI endpoints (`/papers`, `/query`, `/author`, `/visualize`)
   * Streamlit chat + visualization frontend

---

## Database Schema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       papers        â”‚       â”‚       authors        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ id (PK)             â”‚       â”‚ id (PK)              â”‚
â”‚ filename            â”‚       â”‚ name (UNIQUE)        â”‚
â”‚ title               â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ abstract            â”‚               â–²
â”‚ year                â”‚               â”‚
â”‚ venue               â”‚               â”‚
â”‚ path                â”‚               â”‚
â”‚ created_at          â”‚               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
          â”‚                           â”‚
          â–¼                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    paper_authors      â”‚   â”‚     paper_chunks       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ paper_id (FKâ†’papers)  â”‚   â”‚ id (PK)                â”‚
â”‚ author_id (FKâ†’authors)â”‚   â”‚ paper_id (FKâ†’papers)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ section                â”‚
                            â”‚ chunk_index            â”‚
                            â”‚ content                â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

* **papers** â†’ stores global metadata.
* **authors** â†’ unique author names (linked across papers).
* **paper_authors** â†’ many-to-many relation between papers & authors.
* **paper_chunks** â†’ sectioned + chunked content for embedding.

---

## Tech Stack

* **LLM Orchestration** â†’ LangChain, LangGraph
* **LLM Provider** â†’ Gemini (2.5 Flash / Pro, configurable)
* **Backend** â†’ FastAPI
* **Vector Store** â†’ ChromaDB / Weaviate
* **Database** â†’ Postgres (persistent metadata & author graph)
* **UI** â†’ Streamlit + Plotly (charts & visualizations)
* **Infra** â†’ Docker, GitHub Actions, Kubernetes (future)

---

## Setup

```bash
# clone repo
git clone https://github.com/<your-username>/ReadX.git
cd ReadX

# setup virtual environment
python3 -m venv .venv
source .venv/bin/activate

# install dependencies
pip install -r requirements.txt

# (optional) start GROBID (Docker)
docker run -it -p 8070:8070 lfoppiano/grobid:0.7.2

# start postgres (if local)
brew services start postgresql@15

# run backend
uvicorn app.main:app --reload

# run UI
streamlit run ui/streamlit_app.py
```

---

## Next Steps

* Add TEI body chunking (structured section-level chunks from GROBID)
* Improve author disambiguation (affiliations, emails)
* Add LLM-powered synthesis (`Gemini`) into `/query/ask`
* Expand visualization layer (method diagrams, results plots)

---
